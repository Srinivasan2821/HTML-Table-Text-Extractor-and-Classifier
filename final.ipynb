{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from the column with the highest word count in an HTML table\n",
    "def extract_column_with_highest_word_count(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')  # Find the first table in the HTML file\n",
    "            if not table:\n",
    "                print(f\"No table found in the HTML file: {file_path}\")\n",
    "                return None\n",
    "\n",
    "            rows = table.find_all('tr')  # Find all rows in the table\n",
    "            if not rows:\n",
    "                print(f\"No rows found in the table: {file_path}\")\n",
    "                return None\n",
    "\n",
    "            # Initialize a list to store columns' data\n",
    "            columns_data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')  # Find all cells in the row\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if len(columns_data) <= i:\n",
    "                        columns_data.append([])\n",
    "                    columns_data[i].append(cell.get_text(separator=' ').strip())  # Store the text of each cell\n",
    "\n",
    "            # Count words in each column\n",
    "            word_counts = [sum(len(re.findall(r'\\b\\w+\\b', cell)) for cell in column) for column in columns_data]\n",
    "\n",
    "            # Find the column with the highest word count\n",
    "            max_word_count_index = word_counts.index(max(word_counts))\n",
    "            highest_word_count_column = columns_data[max_word_count_index]\n",
    "\n",
    "            # Filter out entries that contain numbers\n",
    "            filtered_column = [cell for cell in highest_word_count_column if not re.search(r'\\d', cell)]\n",
    "\n",
    "            return ' '.join(filtered_column)  # Return the text of the column as a single string\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the file {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the extracted text into a bag-of-words summary\n",
    "def extract_and_summarize_bow(extracted_text):\n",
    "    try:\n",
    "        vectorizer = CountVectorizer()\n",
    "        bow_matrix = vectorizer.fit_transform([extracted_text])  # Convert text to BoW matrix\n",
    "\n",
    "        # Method 1: Total Word Count\n",
    "        total_word_count = bow_matrix.sum()  # Sum of word counts\n",
    "\n",
    "        return total_word_count\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during BoW summarization: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all HTML files in a given folder\n",
    "def process_html_files_in_folder(folder_path):\n",
    "    results = []\n",
    "    for subdir, _, files in os.walk(folder_path):  # Iterate through the folder and its subdirectories\n",
    "        for file in files:\n",
    "            if file.endswith('.html'):  # Process only HTML files\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                extracted_text = extract_column_with_highest_word_count(file_path)  # Extract text from the HTML file\n",
    "                if extracted_text:\n",
    "                    bow_summary = extract_and_summarize_bow(extracted_text)  # Summarize the text to a single value\n",
    "                    folder_name = os.path.basename(subdir)  # Get the name of the folder\n",
    "                    results.append({\n",
    "                        'file_name': file,\n",
    "                        'bag_of_words': bow_summary,\n",
    "                        'folder_name': folder_name\n",
    "                    })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the results to a CSV file\n",
    "def save_results_to_csv(results, output_csv):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)  # Save the results to a CSV file without the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n",
      "An error occurred during BoW summarization: empty vocabulary; perhaps the documents only contain stop words\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "folder_paths = [\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Balance Sheets',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Cash Flow',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Notes',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Income Statement',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Others'\n",
    "]\n",
    "output_csv = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\output.csv'\n",
    "\n",
    "all_results = []\n",
    "for folder_path in folder_paths:\n",
    "    results = process_html_files_in_folder(folder_path)  # Process each folder\n",
    "    all_results.extend(results)  # Collect all results\n",
    "\n",
    "save_results_to_csv(all_results, output_csv)  # Save all results to a single CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elcot\\AppData\\Local\\Temp\\ipykernel_4892\\1797048581.py:85: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['extracted_text'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "# Function to extract text from the column with the highest word count in an HTML table\n",
    "def extract_column_with_highest_word_count(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "            if not table:\n",
    "                print(f\"No table found in the HTML file: {file_path}\")\n",
    "                return None\n",
    "\n",
    "            rows = table.find_all('tr')\n",
    "            if not rows:\n",
    "                print(f\"No rows found in the table: {file_path}\")\n",
    "                return None\n",
    "\n",
    "            columns_data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if len(columns_data) <= i:\n",
    "                        columns_data.append([])\n",
    "                    columns_data[i].append(cell.get_text(separator=' ').strip())\n",
    "\n",
    "            word_counts = [sum(len(re.findall(r'\\b\\w+\\b', cell)) for cell in column) for column in columns_data]\n",
    "            max_word_count_index = word_counts.index(max(word_counts))\n",
    "            highest_word_count_column = columns_data[max_word_count_index]\n",
    "            filtered_column = [cell for cell in highest_word_count_column if not re.search(r'\\d', cell)]\n",
    "\n",
    "            return ' '.join(filtered_column)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process all HTML files in a given folder\n",
    "def process_html_files_in_folder(folder_path):\n",
    "    results = []\n",
    "    for subdir, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.html'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                extracted_text = extract_column_with_highest_word_count(file_path)\n",
    "                if extracted_text:\n",
    "                    folder_name = os.path.basename(subdir)\n",
    "                    results.append({\n",
    "                        'file_name': file,\n",
    "                        'extracted_text': extracted_text,\n",
    "                        'folder_name': folder_name\n",
    "                    })\n",
    "    return results\n",
    "\n",
    "# Function to save the results to a CSV file\n",
    "def save_results_to_csv(results, output_csv):\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Example usage\n",
    "folder_paths = [\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Balance Sheets',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Cash Flow',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Notes',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Income Statement',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Others'\n",
    "]\n",
    "output_csv = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\output.csv'\n",
    "\n",
    "all_results = []\n",
    "for folder_path in folder_paths:\n",
    "    results = process_html_files_in_folder(folder_path)\n",
    "    all_results.extend(results)\n",
    "\n",
    "# Save the extracted texts to a CSV\n",
    "temp_csv = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\temp_extracted_texts.csv'\n",
    "save_results_to_csv(all_results, temp_csv)\n",
    "\n",
    "# Load the CSV and create TF-IDF features\n",
    "df = pd.read_csv(temp_csv)\n",
    "\n",
    "# Fill NaN values in the extracted_text column with an empty string\n",
    "df['extracted_text'].fillna('', inplace=True)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['extracted_text'])\n",
    "\n",
    "# Add TF-IDF features to the DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "df = pd.concat([df, tfidf_df], axis=1)\n",
    "df.drop(columns=['extracted_text'], inplace=True)  # Drop the text column if not needed\n",
    "\n",
    "# Save the final DataFrame with TF-IDF features\n",
    "final_output_csv = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\final_output.csv'\n",
    "df.to_csv(final_output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
