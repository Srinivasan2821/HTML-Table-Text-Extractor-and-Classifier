{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_html(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            return soup.get_text(separator=' ')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_text_from_column_with_words(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "            if not table:\n",
    "                print(\"No table found in the HTML file.\")\n",
    "                return None\n",
    "\n",
    "            # Find all rows in the table\n",
    "            rows = table.find_all('tr')\n",
    "            if not rows:\n",
    "                print(\"No rows found in the table.\")\n",
    "                return None\n",
    "\n",
    "            # Initialize a list to store columns' data\n",
    "            columns_data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all(['td', 'th'])\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if len(columns_data) <= i:\n",
    "                        columns_data.append([])\n",
    "                    columns_data[i].append(cell.get_text(separator=' ').strip())\n",
    "\n",
    "            # Function to check if a list of strings contains only words (no numbers)\n",
    "            def contains_only_words(column):\n",
    "                for cell in column:\n",
    "                    if re.search(r'\\d', cell):\n",
    "                        return False\n",
    "                return True\n",
    "\n",
    "            # Find the first column that contains only words\n",
    "            for column in columns_data:\n",
    "                if contains_only_words(column):\n",
    "                    return ' '.join(column)\n",
    "\n",
    "            print(\"No column found that contains only words.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters (except spaces)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_text_from_html(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            raw_text = soup.get_text(separator=' ')\n",
    "            return preprocess_text(raw_text)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_text_from_html(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            text = soup.get_text(separator=' ')\n",
    "            \n",
    "            # Filter out segments containing numbers\n",
    "            words_only_text = ' '.join(word for word in text.split() if not re.search(r'\\d', word))\n",
    "            \n",
    "            return words_only_text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_first_column_text_without_numbers(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "            if not table:\n",
    "                print(\"No table found in the HTML file.\")\n",
    "                return None\n",
    "\n",
    "            # Extract text from the first column\n",
    "            first_column_text = []\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    first_cell_text = cells[0].get_text(separator=' ').strip()\n",
    "                    if not re.search(r'\\d', first_cell_text):  # Check if the cell text contains numbers\n",
    "                        first_column_text.append(first_cell_text)\n",
    "\n",
    "            return ' '.join(first_column_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def extract_column_with_highest_word_count(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "            if not table:\n",
    "                print(\"No table found in the HTML file.\")\n",
    "                return None\n",
    "\n",
    "            rows = table.find_all('tr')\n",
    "            if not rows:\n",
    "                print(\"No rows found in the table.\")\n",
    "                return None\n",
    "\n",
    "            # Initialize a list to store columns' data\n",
    "            columns_data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if len(columns_data) <= i:\n",
    "                        columns_data.append([])\n",
    "                    columns_data[i].append(cell.get_text(separator=' ').strip())\n",
    "\n",
    "            # Count words in each column\n",
    "            word_counts = [sum(len(re.findall(r'\\b\\w+\\b', cell)) for cell in column) for column in columns_data]\n",
    "\n",
    "            # Find the column with the highest word count\n",
    "            max_word_count_index = word_counts.index(max(word_counts))\n",
    "            highest_word_count_column = columns_data[max_word_count_index]\n",
    "\n",
    "            # Filter out entries that contain numbers\n",
    "            filtered_column = [cell for cell in highest_word_count_column if not re.search(r'\\d', cell)]\n",
    "\n",
    "            return ' '.join(filtered_column)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def convert_to_bag_of_words(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    text_corpus = [text]\n",
    "    bow_matrix = vectorizer.fit_transform(text_corpus)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    bow_array = bow_matrix.toarray()\n",
    "\n",
    "    return bow_array, feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Array:\n",
      " [[ 1  3 10  1  1  1  2  2  2 13  1  1  5  1  8  5  3  1  1  1  1  1 12  1\n",
      "   2  2  2  6  9  1  1  1  1  1  2  1  1  2  1  2  4  1  6  2  1]]\n",
      "Feature Names:\n",
      " ['above' 'and' 'assets' 'balances' 'bank' 'bj' 'borrowings' 'capital'\n",
      " 'cash' 'current' 'deferred' 'equipment' 'equity' 'equivalents'\n",
      " 'financial' 'ii' 'iii' 'in' 'intangible' 'inventories' 'investments'\n",
      " 'ivj' 'liabilities' 'liability' 'loans' 'long' 'net' 'non' 'other'\n",
      " 'particulars' 'payables' 'plant' 'progress' 'property' 'provisions'\n",
      " 'receivables' 'share' 'short' 'standalone' 'tax' 'term' 'than' 'total'\n",
      " 'trade' 'work']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Balance Sheets\\18320959_3.html'\n",
    "extracted_text = extract_column_with_highest_word_count(file_path)\n",
    "if extracted_text:\n",
    "    bow_array, feature_names = convert_to_bag_of_words(extracted_text)\n",
    "    print(\"Bag-of-Words Array:\\n\", bow_array)\n",
    "    print(\"Feature Names:\\n\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Word Count: 127\n",
      "Average Word Frequency: 2.8222222222222206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def extract_and_summarize_bow(extracted_text):\n",
    "    try:\n",
    "        vectorizer = CountVectorizer()\n",
    "        bow_matrix = vectorizer.fit_transform([extracted_text])\n",
    "\n",
    "        # Method 1: Total Word Count\n",
    "        total_word_count = bow_matrix.sum()\n",
    "\n",
    "        # Method 2: Average Word Frequency\n",
    "        average_word_frequency = bow_matrix.mean()\n",
    "\n",
    "        return total_word_count, average_word_frequency\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "file_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Balance Sheets\\18320959_3.html'\n",
    "extracted_text = extract_column_with_highest_word_count(file_path)\n",
    "if extracted_text:\n",
    "    total_word_count, average_word_frequency = extract_and_summarize_bow(extracted_text)\n",
    "    print(\"Total Word Count:\", total_word_count)\n",
    "    print(\"Average Word Frequency:\", average_word_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     17\u001b[0m texts \u001b[38;5;241m=\u001b[39m extracted_text\n\u001b[1;32m---> 18\u001b[0m total_word_count, average_word_frequency \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_single_value_bow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Word Count:\u001b[39m\u001b[38;5;124m\"\u001b[39m, total_word_count)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Word Frequency:\u001b[39m\u001b[38;5;124m\"\u001b[39m, average_word_frequency)\n",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36mcalculate_single_value_bow\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_single_value_bow\u001b[39m(texts):\n\u001b[0;32m      5\u001b[0m     vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[1;32m----> 6\u001b[0m     bow_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Method 1: Total Word Count\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     total_word_count \u001b[38;5;241m=\u001b[39m bow_matrix\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\elcot\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elcot\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1352\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;66;03m# We intentionally don't call the transform method to make\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;66;03m# fit_transform overridable without unwanted side effects in\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;66;03m# TfidfVectorizer.\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(raw_documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable over raw text documents expected, string object received.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1354\u001b[0m     )\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_ngram_range()\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def calculate_single_value_bow(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_matrix = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    # Method 1: Total Word Count\n",
    "    total_word_count = bow_matrix.sum()\n",
    "\n",
    "    # Method 2: Average Word Frequency\n",
    "    average_word_frequency = bow_matrix.mean()\n",
    "\n",
    "    return total_word_count, average_word_frequency\n",
    "\n",
    "# Example usage\n",
    "texts = extracted_text\n",
    "total_word_count, average_word_frequency = calculate_single_value_bow(texts)\n",
    "print(\"Total Word Count:\", total_word_count)\n",
    "print(\"Average Word Frequency:\", average_word_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standalone Particulars A Assets (a) Property, Plant and Equipment (b) Capital work in progress (c) Intangible assets (d) Financial assets (i) Non-current investments (ii) Loans (iii) Other financial assets (e) Other non-current assets  Total Non-Current Assets (A)  (a) Inventories (b) Financial assets (i) Trade Receivables (ii) Cash and cash equivalents (iii) Bank balances other than (ii) above (ivj Loans (v) Other Financial assets (c) Other current assets  Total Current Assets (B)  B Equity & Liabilities  (a) Equity share capital (b) Other Equity  Total Equity (A)  Non-Current Liabilities (a) Financial Liabilities (i) Long term borrowings (ii) Other Non Current Financial Liability (bj Long term provisions (c) Deferred tax liabilities (Net)  Total Non-Current Liabilities (B)  Current Liabilities (a) Financial Liabilities (i) Short term borrowings (ii) Trade payables (iii) Other Current Financial liabilities (b) Other current liabilities (c)Short term provisions (d) Current tax liabilities (Net)  Total Current Liabilities (C) Total Equity and Liabilities (A)+ (B)  +( C)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Balance Sheets\\18320959_3.html'  # Replace with the actual file path\n",
    "extracted_text = extract_column_with_highest_word_count(file_path)\n",
    "print(extracted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
