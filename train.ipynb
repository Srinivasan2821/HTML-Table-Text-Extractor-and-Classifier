{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_csv = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\final_output.csv'\n",
    "df=pd.read_csv(final_output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>folder_name</th>\n",
       "      <th>__</th>\n",
       "      <th>___</th>\n",
       "      <th>_____</th>\n",
       "      <th>________</th>\n",
       "      <th>__________________________</th>\n",
       "      <th>_equity</th>\n",
       "      <th>_i</th>\n",
       "      <th>aa</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zircon</th>\n",
       "      <th>zm</th>\n",
       "      <th>zo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zozila</th>\n",
       "      <th>zr</th>\n",
       "      <th>zrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18320959_3.html</td>\n",
       "      <td>Balance Sheets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18391125_2.html</td>\n",
       "      <td>Balance Sheets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18442877_5.html</td>\n",
       "      <td>Balance Sheets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18445487_2.html</td>\n",
       "      <td>Balance Sheets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18445494_3.html</td>\n",
       "      <td>Balance Sheets</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>18964858_6.html</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>18964858_7.html</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>18964858_8.html</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>19213523_4.html</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>19213523_5.html</td>\n",
       "      <td>Others</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2314 rows Ã— 6150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name     folder_name   __  ___  _____  ________  \\\n",
       "0     18320959_3.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "1     18391125_2.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "2     18442877_5.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "3     18445487_2.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "4     18445494_3.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "...               ...             ...  ...  ...    ...       ...   \n",
       "2309  18964858_6.html          Others  0.0  0.0    0.0       0.0   \n",
       "2310  18964858_7.html          Others  0.0  0.0    0.0       0.0   \n",
       "2311  18964858_8.html          Others  0.0  0.0    0.0       0.0   \n",
       "2312  19213523_4.html          Others  0.0  0.0    0.0       0.0   \n",
       "2313  19213523_5.html          Others  0.0  0.0    0.0       0.0   \n",
       "\n",
       "      __________________________  _equity   _i   aa  ...  zealand  zimbabwe  \\\n",
       "0                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "1                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "3                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "4                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "...                          ...      ...  ...  ...  ...      ...       ...   \n",
       "2309                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2310                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2311                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2312                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2313                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "\n",
       "      zinc  zircon   zm   zo  zone  zozila   zr  zrt  \n",
       "0      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "1      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "3      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "4      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "...    ...     ...  ...  ...   ...     ...  ...  ...  \n",
       "2309   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2310   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2311   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2312   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2313   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "\n",
       "[2314 rows x 6150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2314 entries, 0 to 2313\n",
      "Columns: 6150 entries, file_name to zrt\n",
      "dtypes: float64(6148), object(2)\n",
      "memory usage: 108.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file_name      0\n",
       "folder_name    0\n",
       "__             0\n",
       "___            0\n",
       "_____          0\n",
       "              ..\n",
       "zo             0\n",
       "zone           0\n",
       "zozila         0\n",
       "zr             0\n",
       "zrt            0\n",
       "Length: 6150, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of             file_name     folder_name   __  ___  _____  ________  \\\n",
       "0     18320959_3.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "1     18391125_2.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "2     18442877_5.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "3     18445487_2.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "4     18445494_3.html  Balance Sheets  0.0  0.0    0.0       0.0   \n",
       "...               ...             ...  ...  ...    ...       ...   \n",
       "2309  18964858_6.html          Others  0.0  0.0    0.0       0.0   \n",
       "2310  18964858_7.html          Others  0.0  0.0    0.0       0.0   \n",
       "2311  18964858_8.html          Others  0.0  0.0    0.0       0.0   \n",
       "2312  19213523_4.html          Others  0.0  0.0    0.0       0.0   \n",
       "2313  19213523_5.html          Others  0.0  0.0    0.0       0.0   \n",
       "\n",
       "      __________________________  _equity   _i   aa  ...  zealand  zimbabwe  \\\n",
       "0                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "1                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "3                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "4                            0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "...                          ...      ...  ...  ...  ...      ...       ...   \n",
       "2309                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2310                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2311                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2312                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "2313                         0.0      0.0  0.0  0.0  ...      0.0       0.0   \n",
       "\n",
       "      zinc  zircon   zm   zo  zone  zozila   zr  zrt  \n",
       "0      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "1      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "3      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "4      0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "...    ...     ...  ...  ...   ...     ...  ...  ...  \n",
       "2309   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2310   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2311   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2312   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "2313   0.0     0.0  0.0  0.0   0.0     0.0  0.0  0.0  \n",
       "\n",
       "[2314 rows x 6150 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Balance Sheets', 'Cash Flow', 'Notes', 'Income Statement',\n",
       "       'Others'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"folder_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['file_name', 'folder_name'])\n",
    "y = df['folder_name']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Select top k features\n",
    "k = 500  # Adjust k based on your needs\n",
    "selector = SelectKBest(chi2, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Balance Sheets       0.92      0.96      0.94        81\n",
      "       Cash Flow       0.90      0.82      0.86        11\n",
      "Income Statement       0.98      0.90      0.94        91\n",
      "           Notes       0.83      0.78      0.80       185\n",
      "          Others       0.87      0.91      0.89       327\n",
      "\n",
      "        accuracy                           0.88       695\n",
      "       macro avg       0.90      0.87      0.89       695\n",
      "    weighted avg       0.88      0.88      0.88       695\n",
      "\n",
      "Accuracy: 0.8776978417266187\n",
      "--------------------------------------------------------------------------------\n",
      "Results for Random Forest:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Balance Sheets       0.96      0.98      0.97        81\n",
      "       Cash Flow       1.00      0.91      0.95        11\n",
      "Income Statement       0.99      0.86      0.92        91\n",
      "           Notes       0.87      0.81      0.84       185\n",
      "          Others       0.87      0.93      0.90       327\n",
      "\n",
      "        accuracy                           0.89       695\n",
      "       macro avg       0.94      0.90      0.92       695\n",
      "    weighted avg       0.90      0.89      0.89       695\n",
      "\n",
      "Accuracy: 0.8949640287769784\n",
      "--------------------------------------------------------------------------------\n",
      "Results for SVM:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Balance Sheets       0.96      0.94      0.95        81\n",
      "       Cash Flow       1.00      0.27      0.43        11\n",
      "Income Statement       0.99      0.86      0.92        91\n",
      "           Notes       0.81      0.83      0.82       185\n",
      "          Others       0.87      0.92      0.89       327\n",
      "\n",
      "        accuracy                           0.88       695\n",
      "       macro avg       0.93      0.76      0.80       695\n",
      "    weighted avg       0.88      0.88      0.88       695\n",
      "\n",
      "Accuracy: 0.8776978417266187\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': make_pipeline(StandardScaler(), LogisticRegression(random_state=42)),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': make_pipeline(StandardScaler(), SVC(random_state=42))\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print('-' * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters found:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation score:  0.9042655658754729\n",
      "Results for the best Random Forest model:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Balance Sheets       0.96      0.95      0.96        81\n",
      "       Cash Flow       1.00      0.91      0.95        11\n",
      "Income Statement       0.99      0.86      0.92        91\n",
      "           Notes       0.85      0.83      0.84       185\n",
      "          Others       0.87      0.92      0.90       327\n",
      "\n",
      "        accuracy                           0.89       695\n",
      "       macro avg       0.93      0.89      0.91       695\n",
      "    weighted avg       0.89      0.89      0.89       695\n",
      "\n",
      "Accuracy: 0.8920863309352518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Example: Hyperparameter tuning for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test_selected)\n",
    "print(\"Results for the best Random Forest model:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize and fit the TF-IDF vectorizer with reduced max_features\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Convert the vocabulary dictionary into a DataFrame\n",
    "vectorizer_df = pd.DataFrame(vectorizer.vocabulary_.items(), columns=['word', 'index'])\n",
    "\n",
    "# Save the TF-IDF vectorizer vocabulary as CSV\n",
    "vectorizer_csv_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\tfidf_vectorizer.csv'\n",
    "vectorizer_df.to_csv(vectorizer_csv_path, index=False)\n",
    "\n",
    "# Optional: To load the TF-IDF vectorizer from CSV later, you can use:\n",
    "# vectorizer_df = pd.read_csv(vectorizer_csv_path)\n",
    "# vectorizer = TfidfVectorizer(vocabulary=vectorizer_df.set_index('word').to_dict()['index'])\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\best_model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(best_rf_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the TF-IDF vectorizer as a pickle file\n",
    "vectorizer_pkl_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\tfidf_vectorizer.pkl'\n",
    "with open(vectorizer_pkl_path, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Balance Sheets       0.96      0.96      0.96        54\n",
      "       Cash Flow       1.00      0.86      0.92         7\n",
      "Income Statement       0.96      0.90      0.93        61\n",
      "           Notes       0.86      0.87      0.87       123\n",
      "          Others       0.90      0.92      0.91       218\n",
      "\n",
      "        accuracy                           0.91       463\n",
      "       macro avg       0.94      0.90      0.92       463\n",
      "    weighted avg       0.91      0.91      0.91       463\n",
      "\n",
      "Accuracy: 0.9071274298056156\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'text' and 'folder_name'\n",
    "# where 'text' contains the text data and 'folder_name' contains the class labels\n",
    "\n",
    "# Step 1: Load your dataset or create a DataFrame 'df'\n",
    "# For example:\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['folder_name'], test_size=0.2, random_state=42, stratify=df['folder_name'])\n",
    "\n",
    "# Step 3: Initialize and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Initialize and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE: Counter({'Others': 869, 'Notes': 494, 'Income Statement': 243, 'Balance Sheets': 216, 'Cash Flow': 29})\n",
      "Class distribution after SMOTE: Counter({'Others': 869, 'Balance Sheets': 869, 'Notes': 869, 'Income Statement': 869, 'Cash Flow': 869})\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  Balance Sheets       0.96      0.94      0.95        54\n",
      "       Cash Flow       1.00      0.86      0.92         7\n",
      "Income Statement       0.97      0.92      0.94        61\n",
      "           Notes       0.83      0.90      0.87       123\n",
      "          Others       0.92      0.90      0.91       218\n",
      "\n",
      "        accuracy                           0.91       463\n",
      "       macro avg       0.94      0.90      0.92       463\n",
      "    weighted avg       0.91      0.91      0.91       463\n",
      "\n",
      "Accuracy: 0.9071274298056156\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Function to extract text from the column with the highest word count in an HTML table\n",
    "def extract_column_with_highest_word_count(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "            if not table:\n",
    "                return None\n",
    "\n",
    "            rows = table.find_all('tr')\n",
    "            if not rows:\n",
    "                return None\n",
    "\n",
    "            columns_data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if len(columns_data) <= i:\n",
    "                        columns_data.append([])\n",
    "                    columns_data[i].append(cell.get_text(separator=' ').strip())\n",
    "\n",
    "            word_counts = [sum(len(re.findall(r'\\b\\w+\\b', cell)) for cell in column) for column in columns_data]\n",
    "            max_word_count_index = word_counts.index(max(word_counts))\n",
    "            highest_word_count_column = columns_data[max_word_count_index]\n",
    "            filtered_column = [cell for cell in highest_word_count_column if not re.search(r'\\d', cell)]\n",
    "\n",
    "            return ' '.join(filtered_column)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Paths to your folders\n",
    "folder_paths = [\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Balance Sheets',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Cash Flow',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Notes',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Income Statement',\n",
    "    r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Others'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "data = {'file_path': [], 'text': [], 'folder_name': []}\n",
    "\n",
    "# Iterate through each folder and each file\n",
    "for folder_path in folder_paths:\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        extracted_text = extract_column_with_highest_word_count(file_path)\n",
    "        if extracted_text:\n",
    "            data['file_path'].append(file_path)\n",
    "            data['text'].append(extracted_text)\n",
    "            data['folder_name'].append(folder_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure 'text' column is present and there are no null values\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Step 1: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['folder_name'], test_size=0.2, random_state=42, stratify=df['folder_name'])\n",
    "\n",
    "# Step 2: Initialize and fit the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 3: Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_tfidf_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Check the class distribution after applying SMOTE\n",
    "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_resampled))\n",
    "\n",
    "# Step 4: Initialize and train the RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "clf.fit(X_train_tfidf_resampled, y_train_resampled)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "vectorizer_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\tfidf_vectorizer.pkl'\n",
    "with open(vectorizer_path, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "# Save the model\n",
    "model_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\best_model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the file is: Cash Flow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# Function to extract text from the column with the highest word count in an HTML table\n",
    "def extract_column_with_highest_word_count(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "            if not table:\n",
    "                return None\n",
    "\n",
    "            rows = table.find_all('tr')\n",
    "            if not rows:\n",
    "                return None\n",
    "\n",
    "            columns_data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                for i, cell in enumerate(cells):\n",
    "                    if len(columns_data) <= i:\n",
    "                        columns_data.append([])\n",
    "                    columns_data[i].append(cell.get_text(separator=' ').strip())\n",
    "\n",
    "            word_counts = [sum(len(re.findall(r'\\b\\w+\\b', cell)) for cell in column) for column in columns_data]\n",
    "            max_word_count_index = word_counts.index(max(word_counts))\n",
    "            highest_word_count_column = columns_data[max_word_count_index]\n",
    "            filtered_column = [cell for cell in highest_word_count_column if not re.search(r'\\d', cell)]\n",
    "\n",
    "            return ' '.join(filtered_column)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Load the saved model\n",
    "model_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\best_model.pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Assuming the TF-IDF vectorizer was also saved\n",
    "vectorizer_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\tfidf_vectorizer.pkl'\n",
    "with open(vectorizer_path, 'rb') as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "# Function to classify a new HTML file\n",
    "def classify_html_file(file_path):\n",
    "    extracted_text = extract_column_with_highest_word_count(file_path)\n",
    "    if extracted_text:\n",
    "        # Transform the extracted text using the TF-IDF vectorizer\n",
    "        transformed_text = vectorizer.transform([extracted_text])\n",
    "        \n",
    "        # Predict the class using the loaded model\n",
    "        prediction = loaded_model.predict(transformed_text)\n",
    "        return prediction[0]\n",
    "    else:\n",
    "        return \"Unable to extract text\"\n",
    "\n",
    "# Example usage\n",
    "new_html_file_path = r'C:\\Users\\elcot\\Desktop\\VS Code\\Projects\\Table Classification\\data\\Cash Flow\\18599651_table_161.html'  \n",
    "predicted_class = classify_html_file(new_html_file_path)\n",
    "print(f\"The predicted class for the file is: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
